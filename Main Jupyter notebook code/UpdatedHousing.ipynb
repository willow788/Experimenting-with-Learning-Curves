{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7876,"sourceType":"datasetVersion","datasetId":5227}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-31T12:49:26.878391Z","iopub.execute_input":"2025-12-31T12:49:26.878791Z","iopub.status.idle":"2025-12-31T12:49:28.512653Z","shell.execute_reply.started":"2025-12-31T12:49:26.878737Z","shell.execute_reply":"2025-12-31T12:49:28.511623Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import fetch_california_housing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import mean_squared_error\nprint(\"all required things are installed\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T12:49:36.052760Z","iopub.execute_input":"2025-12-31T12:49:36.053056Z","iopub.status.idle":"2025-12-31T12:49:37.295955Z","shell.execute_reply.started":"2025-12-31T12:49:36.053031Z","shell.execute_reply":"2025-12-31T12:49:37.294705Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv(\"/kaggle/input/california-housing-prices/housing.csv\")\n\ndf = df.copy()\n\ndf[\"total_bedrooms\"] = df[\"total_bedrooms\"].fillna(df[\"total_bedrooms\"].median())\n\n#one hot enchoded one parameter\ndf = pd.get_dummies(df, columns= [\"ocean_proximity\"] , drop_first= True )\n\nprint(\"done here\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T12:49:40.160200Z","iopub.execute_input":"2025-12-31T12:49:40.160773Z","iopub.status.idle":"2025-12-31T12:49:40.254464Z","shell.execute_reply.started":"2025-12-31T12:49:40.160741Z","shell.execute_reply":"2025-12-31T12:49:40.253168Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nX = df.drop(\"median_house_value\" , axis= 1)  #spliting features\ny = df[\"median_house_value\"]                 #target\n\n#this is not the spliting the datasets\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T12:49:42.996813Z","iopub.execute_input":"2025-12-31T12:49:42.997114Z","iopub.status.idle":"2025-12-31T12:49:43.006685Z","shell.execute_reply.started":"2025-12-31T12:49:42.997090Z","shell.execute_reply":"2025-12-31T12:49:43.005044Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#now we will spliting the dataset into two halves\n#split A: 80-20\n#split B : 40-60\n\nX_train_A, X_test_A, y_train_A, y_test_A = train_test_split(\n    X, y, train_size= 0.8, random_state= 42\n)\n\nX_train_B , X_test_B, y_train_B, y_test_B = train_test_split(\n    X, y, train_size= 0.4, random_state= 42\n)\n\nprint(\"Both data spliting is done!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T12:49:45.439729Z","iopub.execute_input":"2025-12-31T12:49:45.440072Z","iopub.status.idle":"2025-12-31T12:49:45.456522Z","shell.execute_reply.started":"2025-12-31T12:49:45.440043Z","shell.execute_reply":"2025-12-31T12:49:45.455299Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#model fitting wtih both of the data\n\nmodel_A = LinearRegression()\nmodel_A.fit(X_train_A, y_train_A)\n\nmodel_B = LinearRegression()\nmodel_B.fit(X_train_B, y_train_B)\n\nprint(\"model trained\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T12:49:49.685162Z","iopub.execute_input":"2025-12-31T12:49:49.685525Z","iopub.status.idle":"2025-12-31T12:49:49.726423Z","shell.execute_reply.started":"2025-12-31T12:49:49.685494Z","shell.execute_reply":"2025-12-31T12:49:49.725580Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#predictions of the models\n\ny_pred_A = model_A.predict(X_test_A)\ny_pred_B = model_B.predict(X_test_B)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T12:49:53.036580Z","iopub.execute_input":"2025-12-31T12:49:53.036882Z","iopub.status.idle":"2025-12-31T12:49:53.047075Z","shell.execute_reply.started":"2025-12-31T12:49:53.036858Z","shell.execute_reply":"2025-12-31T12:49:53.045973Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#EVALUATION OF THE ERRORS\n\nfrom sklearn.metrics import r2_score\n\nmse_A = mean_squared_error(y_test_A, y_pred_A)\nr2_A = r2_score(y_test_A, y_pred_A)\n\nmse_B = mean_squared_error(y_test_B, y_pred_B)\nr2_B = r2_score(y_test_B, y_pred_B)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T12:49:55.661681Z","iopub.execute_input":"2025-12-31T12:49:55.661976Z","iopub.status.idle":"2025-12-31T12:49:55.673260Z","shell.execute_reply.started":"2025-12-31T12:49:55.661952Z","shell.execute_reply":"2025-12-31T12:49:55.672224Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"MODEL A MSE\")\nprint(mse_A)\nprint(\"model B  mse\")\nprint(mse_B)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T12:49:59.056560Z","iopub.execute_input":"2025-12-31T12:49:59.057439Z","iopub.status.idle":"2025-12-31T12:49:59.062881Z","shell.execute_reply.started":"2025-12-31T12:49:59.057406Z","shell.execute_reply":"2025-12-31T12:49:59.061839Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#printing the r2 scores\n\nprint(\"r2 score of model A \", r2_A )\nprint(\"r2 score of model B: \" , r2_B)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T12:50:02.805787Z","iopub.execute_input":"2025-12-31T12:50:02.806105Z","iopub.status.idle":"2025-12-31T12:50:02.812151Z","shell.execute_reply.started":"2025-12-31T12:50:02.806080Z","shell.execute_reply":"2025-12-31T12:50:02.810755Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#PLOTING THE 1ST MODEL\nplt.figure(figsize= (12, 6))\n\nplt.subplot(1,2,1)\nplt.scatter(y_test_A, y_pred_A, alpha=0.3)\nplt.xlabel(\"Actual Prices\")\nplt.ylabel(\"Predicted Prices\")\nplt.title(\"Model A: On 80% training data\")\nplt.plot([y_test_A.min(), y_test_A.max()],\n        [y_pred_A.min(), y_pred_A.max()],\n        color=\"red\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T12:50:05.920041Z","iopub.execute_input":"2025-12-31T12:50:05.920800Z","iopub.status.idle":"2025-12-31T12:50:06.198121Z","shell.execute_reply.started":"2025-12-31T12:50:05.920763Z","shell.execute_reply":"2025-12-31T12:50:06.197039Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#plotting the second model\n\nplt.figure(figsize=(12,6))\n\nplt.subplot(1,2,2)\nplt.scatter(y_test_B, y_pred_B, alpha= 0.3)\nplt.xlabel(\"Actual Prices\")\nplt.ylabel(\"Predicted Prices\")\nplt.title(\"Model B : ON 40% training data\")\nplt.plot([y_test_B.min(), y_test_B.max()],\n        [y_pred_B.min(), y_pred_B.max()],\n        color=\"red\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T12:50:10.645194Z","iopub.execute_input":"2025-12-31T12:50:10.645733Z","iopub.status.idle":"2025-12-31T12:50:10.843292Z","shell.execute_reply.started":"2025-12-31T12:50:10.645602Z","shell.execute_reply":"2025-12-31T12:50:10.841974Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#plotting the learning curves\nX_train_full, X_val, y_train_full, y_val = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n\n\n\ntrain_sizes = np.linspace(0.1, 0.9,9)\n\ntrain_errors = []\nval_errors = []\nfor size in train_sizes:\n    X_train_sub, _, y_train_sub, _ = train_test_split(\n        X_train_full, y_train_full,\n        train_size=float(size),      # make it a Python float\n        random_state=42\n    )\n    model = LinearRegression()\n    model.fit(X_train_sub, y_train_sub)\n    y_train_pred = model.predict(X_train_sub)\n    \n    y_val_pred = model.predict(X_val)\n    \n    train_mse = mean_squared_error(y_train_sub, y_train_pred)\n    \n    val_mse = mean_squared_error(y_val, y_val_pred)\n    \n    train_errors.append(train_mse)\n    \n    val_errors.append(val_mse)\n    \n\n\n\n\n\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T13:02:26.558492Z","iopub.execute_input":"2025-12-31T13:02:26.558855Z","iopub.status.idle":"2025-12-31T13:02:26.703158Z","shell.execute_reply.started":"2025-12-31T13:02:26.558824Z","shell.execute_reply":"2025-12-31T13:02:26.702307Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#plotting the learning curves\nplt.figure(figsize = (12,6))\n\nplt.plot(train_sizes, train_errors, marker = \"o\", label= \"Training Error\")\nplt.plot(train_sizes, val_errors, marker = \"o\", label= \"Validation Errors\")\nplt.xlabel(\"Training set size\")\nplt.ylabel(\"MSE\")\nplt.title(\"Learning curves: Curves that show validation errors and training errors\")\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T13:02:39.518647Z","iopub.execute_input":"2025-12-31T13:02:39.518972Z","iopub.status.idle":"2025-12-31T13:02:39.738486Z","shell.execute_reply.started":"2025-12-31T13:02:39.518948Z","shell.execute_reply":"2025-12-31T13:02:39.737442Z"}},"outputs":[],"execution_count":null}]}
